{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc8MmgZugZWR"
      },
      "source": [
        "# **License Plate Detection using Detectron2, PyTorch, Colab, Roboflow and Tesseract**\n",
        "\n",
        "### **Objective**\n",
        "This notebook shows an end to end pipeline for detecting license plates from images using Detectron2, PyTorch, and Tesseract.  It uses Google''c Colab for using GPUs, and Roboflow for generating Coco compatible image dataset.  It also caches weights for a trained model for reuse during inference operations.\n",
        "\n",
        "### **Tools and references**\n",
        "Here are references to the tools used:\n",
        "\n",
        "Cars dataset:  https://www.kaggle.com/andrewmvd/car-plate-detection\n",
        "\n",
        "Detectron2:  https://ai.facebook.com/tools/detectron2/\n",
        "\n",
        "Tesseract:  https://pypi.org/project/pytesseract/\n",
        "\n",
        "Google Colab:  https://research.google.com/colaboratory/faq.html\n",
        "\n",
        "Roboflow:  https://roboflow.com/\n",
        "\n",
        "Coco data format:  https://opencv.org/introduction-to-the-coco-dataset/#:~:text=COCO%20stores%20data%20in%20a,level%20description%20of%20the%20dataset\n",
        "\n",
        "A related reference: https://towardsdatascience.com/object-detection-in-6-steps-using-detectron2-705b92575578\n",
        "\n",
        "Image denoising:  https://stackoverflow.com/questions/37745519/use-pytesseract-ocr-to-recognize-text-from-an-image\n",
        "\n",
        "Computer Vision references:  https://courses.opencv.org/dashboard\n",
        "\n",
        "\n",
        "Links to my dataset:  \n",
        "\n",
        "\n",
        "\n",
        "### **Approach**\n",
        "\n",
        "This notebook uses Google Colab for access to GPUs.  \n",
        "The full pipeline uses the following steps:\n",
        "\n",
        "1.  Mount Colab\n",
        "2.  Install Detectron2 dependencies\n",
        "3.  Install Detectron2\n",
        "4.  Import packages\n",
        "5.  Register Dataset:\n",
        "    The dataset needs to be registered with detectron2 to be used.\n",
        "    The dataset format should be compatible with Coco format (see \n",
        "    references).  We used Roboflow to convert our data to Coco format \n",
        "    (references)\n",
        "6.  Visualize training data.  Visualizing data helps in ensuring we use the right dataset for training which can be computationally expensive.\n",
        "7.  Create CocoTrainer class.\n",
        "8.  Train the model.\n",
        "9.  Inspect training curves in tensorboard.\n",
        "10.  Define predictor and evaluator objects.\n",
        "11.  Save weights for the trained model.\n",
        "12.  List output files.\n",
        "13.  Assign proper weights to configuration object.\n",
        "14.  Denoise image.\n",
        "15.  Infer and visualize predictions.  \n",
        "\n",
        "### **Note** \n",
        "This notebook describes an end to end approach to detect license plates from car images.  I will update these notes with approaches which enhance the accuracy and execution time as I get additional information.\n",
        "\n",
        "###  **Summary**\n",
        "We are usng detectron2 to localize the license plate bounding box of a car.  This localized license plate image is fed to an OCR tool like Tesseract for licens plate detection.  We could improve the accuracy of detection by denoising the image before feeding it to the OCR tool.  Another approach would be to use third party APIs for OCR function like:\n",
        "\n",
        "https://platerecognizer.com/alpr-results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.  Mount colab"
      ],
      "metadata": {
        "id": "TsLkQOdPP8n7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-TWQBNV2Enb"
      },
      "outputs": [],
      "source": [
        "# Note:  Change runtime type to a GPU\n",
        "!pip install kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "print('done')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd6NebZ5hP0A"
      },
      "source": [
        "###2. **Install Detectron2 Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXisIbT1Zqou"
      },
      "outputs": [],
      "source": [
        "#Note:  use cu101 because colab has CUDA 10.1\n",
        "\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "import random\n",
        "#------------------------------\n",
        "# run parameters\n",
        "is_train = 1 # set to 1 for training model for a new dataset, or 0 to use weights from a previous training run\n",
        "model_path = '/content/drive/MyDrive/content2/datasetsAndJNs/text_detection/data/cached_model'\n",
        "max_iter = 1000\n",
        "score_threshold_test = 0.75\n",
        "#-----------------------------------------------\n",
        "train_jsons  =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/train/_annotations.coco.json\"\n",
        "train_images =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/train\"\n",
        "\n",
        "valid_jsons  =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/valid/_annotations.coco.json\"\n",
        "valid_images =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/valid\"\n",
        "\n",
        "test_jsons  =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test/_annotations.coco.json\"\n",
        "test_images =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test\"\n",
        "\n",
        "test_lp_jsons  =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test_lp/_annotations.coco.json\"\n",
        "test_lp_images =  \"/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test_lp\"\n",
        "##-----------------------------------------------------------\n",
        "# train_jsons  =  \"path to your train json file\"\n",
        "# train_images =  \"path to your train images'\n",
        "\n",
        "# valid_jsons  =  \"path to your valid json file\"\n",
        "# valid_images =  \"path to your valid images\"\n",
        "\n",
        "# test_jsons  =  \"path to your test json file\"\n",
        "# test_images =  \"path to your test images\"\n",
        "\n",
        "# test_lp_jsons  =  \"path to your test_lp json file\"\n",
        "# test_lp_images =  \"path to your test_lp images\"\n",
        "#------------------------------------------------------\n",
        "\n",
        "dsv = str(random.randint(0,1000000))  ## dataset version\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.  i**nstall Detectron2**"
      ],
      "metadata": {
        "id": "LSu8KSkbGM4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW8A0IHVZ_MR"
      },
      "outputs": [],
      "source": [
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.  **imports**"
      ],
      "metadata": {
        "id": "KWiF3mO0Gayw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rCUZZnbhcyl"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.catalog import DatasetCatalog\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd0NJiPJhiu7"
      },
      "source": [
        "###*5*. **register datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Mi9gsZzhokl"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "##-------------------------------------------------------------\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/train/_annotations.coco.json\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/train\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/valid/_annotations.coco.json\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/valid\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test/_annotations.coco.json\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test_lp/_annotations.coco.json\n",
        "\n",
        "# !ls /content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco/test_lp\n",
        "\n",
        "register_coco_instances(\"my_dataset_train\" + dsv, {}, train_jsons, train_images)\n",
        "\n",
        "register_coco_instances(\"my_dataset_valid\" + dsv, {}, valid_jsons, valid_images)\n",
        "\n",
        "register_coco_instances(\"my_dataset_test\" + dsv, {}, test_jsons, test_images)\n",
        "\n",
        "register_coco_instances(\"my_dataset_test_lp\" + dsv, {}, test_jsons, test_lp_images)\n",
        "\n",
        "print('done')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6.  **visualize training data**"
      ],
      "metadata": {
        "id": "dyQfnYO3G6rw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdTAusKE9zUQ"
      },
      "outputs": [],
      "source": [
        "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\" + dsv)\n",
        "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\" + dsv)\n",
        "\n",
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    fname = d[\"file_name\"]\n",
        "    img = cv2.imread(fname)\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okQbhIYIh_CL"
      },
      "source": [
        "###7. **train Custom Detectron2 Detector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4UESNQ4tyVm"
      },
      "outputs": [],
      "source": [
        "# We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    coco_eval = '/content/drive/MyDrive/content2/datasetsAndJNs/cars_kaggle/data_coco'\n",
        "    if output_folder is None:\n",
        "        os.makedirs(coco_eval, exist_ok=True)\n",
        "        output_folder = coco_eval\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. **train**"
      ],
      "metadata": {
        "id": "Ke-QqwL9HTXC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg9wYt8ZeLHh"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\" + dsv,)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_valid\" + dsv,) ## datasets.test should be valid dataset\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = max_iter    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "if(is_train==1):\n",
        "  trainer.train()\n",
        "else:\n",
        "  trainer = torch.load(model_path + '/model_final.pth')\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.  **look at training curves in tensorboard**"
      ],
      "metadata": {
        "id": "fuA7UzP7HcLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oca9rEQKif1h"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "###10.  **Define predictor and evaluator objects**"
      ],
      "metadata": {
        "id": "ADa_OrDIHn9Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBUdNVhn1rHh"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "weights_path = cfg.OUTPUT_DIR\n",
        "if(is_train!=1):\n",
        "  weights_path = model_path\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(weights_path, \"model_final.pth\")\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_threshold_test\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_test\" + dsv, cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\" + dsv)\n",
        "if(is_train==1):\n",
        "  inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11,  **save weights**"
      ],
      "metadata": {
        "id": "OWwCRqXPWROH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.checkpoint import DetectionCheckpointer, Checkpointer\n",
        "\n",
        "if (is_train==1):\n",
        "  checkpointer = DetectionCheckpointer(trainer.model, save_dir=model_path)\n",
        "  checkpointer.save(\"model_final\")  \n",
        "#----------------------\n",
        "print('done')\n"
      ],
      "metadata": {
        "id": "vTeXKenoWXL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3BX34iXw1gU"
      },
      "source": [
        "###12. **List output files**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb65zpj87Bka"
      },
      "outputs": [],
      "source": [
        "%ls ./output/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13.  **Assign proper weights to configuration object**\n"
      ],
      "metadata": {
        "id": "QFtNqllmH--v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVBjf0DE7HEW"
      },
      "outputs": [],
      "source": [
        "cfg.DATASETS.TEST = (\"my_dataset_test\" + dsv, )\n",
        "\n",
        "test_metadata = MetadataCatalog.get(\"my_dataset_test\" + dsv)\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14.  **Denoise input image**"
      ],
      "metadata": {
        "id": "cpH-eMK6_t1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "  thresh = cv2.threshold(blur, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  # Morph open to remove noise and invert image\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "  opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "  invert = 255 - opening\n",
        "  return invert"
      ],
      "metadata": {
        "id": "4qR1bNxPz1Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15.  **infer and visualize perdctions**"
      ],
      "metadata": {
        "id": "10qSqCm-IFz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiJ0Ylc_XAUa"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import glob\n",
        "\n",
        "#-------------\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract==0.3.9\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "from PIL import Image\n",
        "import cv2\n",
        "#------------\n",
        "bboxes2 = []\n",
        "ct_cars_detected = 0\n",
        "ct_images = 0\n",
        "cars_undetected = []\n",
        "cars_detected = []\n",
        "cars_lp_detected = []\n",
        "cars_all = []\n",
        "for imageName in glob.glob(test_lp_images + '/*jpg'):\n",
        "  ct_images = ct_images + 1\n",
        "  cars_all.append(imageName)\n",
        "  im = cv2.imread(imageName)\n",
        "  outputs = predictor(im)\n",
        "\n",
        "  output_pred_boxes = outputs[\"instances\"].pred_boxes\n",
        "\n",
        "  for i in output_pred_boxes.__iter__():\n",
        "    bb = i.cpu().numpy()\n",
        "    flag = np.any(bb)\n",
        "    if(flag):\n",
        "        bboxes2.append((imageName, bb))\n",
        "        print('bounding box', bb)\n",
        "        ct_cars_detected = ct_cars_detected + 1\n",
        "        bboxes2.append((imageName, bb))\n",
        "        #-------------------------------------\n",
        "        y1 = int(bb[0])\n",
        "        x1 = int(bb[1])\n",
        "        y2 = int(bb[2])\n",
        "        x2 = int(bb[3])\n",
        "\n",
        "        print('x1,y1,x2, y2', x1, y1, x2, y2)\n",
        "        license_plate = im[x1:x2, y1:y2]\n",
        "        print('image')\n",
        "        cv2_imshow(im)\n",
        "        print('license_plate')\n",
        "        cv2_imshow(license_plate)\n",
        "        im_denoise = denoise(im)\n",
        "\n",
        "        cv2.waitKey(0)\n",
        "        #------------------\n",
        "        lpn = pytesseract.image_to_string(license_plate)\n",
        "        print('license plate number: ', lpn)\n",
        "\n",
        "        # lpn_denoise = pytesseract.image_to_string(im_denoise)\n",
        "        # print('license_plate_number_denoise: ', lpn_denoise)\n",
        "\n",
        "print('done') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}